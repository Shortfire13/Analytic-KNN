{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-07 23:59:58+00:00</td>\n",
       "      <td>young_ladylike</td>\n",
       "      <td>@erikamelfa @jokowi Parah emang...\\nMalah bila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-07 23:59:54+00:00</td>\n",
       "      <td>SastroJoyo1</td>\n",
       "      <td>@Rizmaya__ @jokowi @PDemokrat @SBYudhoyono O.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-07 23:59:47+00:00</td>\n",
       "      <td>oketa214</td>\n",
       "      <td>@jokowi Bangsa Indonesia dengan bapak Jokowi t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-07 23:59:42+00:00</td>\n",
       "      <td>pahlevi0884</td>\n",
       "      <td>Berkolaborasi dengan tiga kementrian tingkatka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-07 23:59:32+00:00</td>\n",
       "      <td>_ikhwanyan</td>\n",
       "      <td>@tvOneNews Pemerintah @jokowi tidak serius lak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime        username  \\\n",
       "0  2022-09-07 23:59:58+00:00  young_ladylike   \n",
       "1  2022-09-07 23:59:54+00:00     SastroJoyo1   \n",
       "2  2022-09-07 23:59:47+00:00        oketa214   \n",
       "3  2022-09-07 23:59:42+00:00     pahlevi0884   \n",
       "4  2022-09-07 23:59:32+00:00      _ikhwanyan   \n",
       "\n",
       "                                             content  \n",
       "0  @erikamelfa @jokowi Parah emang...\\nMalah bila...  \n",
       "1  @Rizmaya__ @jokowi @PDemokrat @SBYudhoyono O.....  \n",
       "2  @jokowi Bangsa Indonesia dengan bapak Jokowi t...  \n",
       "3  Berkolaborasi dengan tiga kementrian tingkatka...  \n",
       "4  @tvOneNews Pemerintah @jokowi tidak serius lak...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "def load_data():\n",
    "    data = pd.read_csv('jokowi.csv')#ubah nama file sesai dengan nama file kalian\n",
    "    return data\n",
    "\n",
    "tweet_df = load_data()\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-07 23:59:58+00:00</td>\n",
       "      <td>young_ladylike</td>\n",
       "      <td>@erikamelfa @jokowi Parah emang...\\nMalah bila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-07 23:59:54+00:00</td>\n",
       "      <td>SastroJoyo1</td>\n",
       "      <td>@Rizmaya__ @jokowi @PDemokrat @SBYudhoyono O.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-07 23:59:47+00:00</td>\n",
       "      <td>oketa214</td>\n",
       "      <td>@jokowi Bangsa Indonesia dengan bapak Jokowi t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-07 23:59:42+00:00</td>\n",
       "      <td>pahlevi0884</td>\n",
       "      <td>Berkolaborasi dengan tiga kementrian tingkatka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-07 23:59:32+00:00</td>\n",
       "      <td>_ikhwanyan</td>\n",
       "      <td>@tvOneNews Pemerintah @jokowi tidak serius lak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime        username  \\\n",
       "0  2022-09-07 23:59:58+00:00  young_ladylike   \n",
       "1  2022-09-07 23:59:54+00:00     SastroJoyo1   \n",
       "2  2022-09-07 23:59:47+00:00        oketa214   \n",
       "3  2022-09-07 23:59:42+00:00     pahlevi0884   \n",
       "4  2022-09-07 23:59:32+00:00      _ikhwanyan   \n",
       "\n",
       "                                             content  \n",
       "0  @erikamelfa @jokowi Parah emang...\\nMalah bila...  \n",
       "1  @Rizmaya__ @jokowi @PDemokrat @SBYudhoyono O.....  \n",
       "2  @jokowi Bangsa Indonesia dengan bapak Jokowi t...  \n",
       "3  Berkolaborasi dengan tiga kementrian tingkatka...  \n",
       "4  @tvOneNews Pemerintah @jokowi tidak serius lak...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "def load_data():\n",
    "    data = pd.read_csv('jokowi.csv')#ubah nama file sesai dengan nama file kalian\n",
    "    return data\n",
    "\n",
    "tweet_df = load_data()\n",
    "tweet_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisi dataframe\n",
    "df  = pd.DataFrame(tweet_df[['datetime','username', 'content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove user \n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt    \n",
    "df['remove_user'] = np.vectorize(remove_pattern)(df['content'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove user\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt    \n",
    "df['remove_user'] = np.vectorize(remove_pattern)(df['content'], \"@[\\w]*\")\n",
    "\n",
    "def remove(tweet):\n",
    "    #remove angka\n",
    "    tweet = re.sub('[0-9]+', '', tweet)\n",
    "    \n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    " \n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    \n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    return tweet\n",
    "df['remove_http'] = df['remove_user'].apply(lambda x: remove(x))\n",
    "df.sort_values(\"remove_http\", inplace = True)\n",
    "df.drop_duplicates(subset =\"remove_http\", keep = 'first', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stopword\n",
    "from nltk.corpus import stopwords \n",
    "stopwords_indonesia = stopwords.words('indonesian')\n",
    " \n",
    "#import sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "#tokenize\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Happy Emoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    " \n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    " \n",
    "# all emoticons (happy + sad)\n",
    "emoticons = emoticons_happy.union(emoticons_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    " \n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    " \n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    \n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    #remove coma\n",
    "    tweet = re.sub(r',','',tweet)\n",
    "    \n",
    "    #remove angka\n",
    "    tweet = re.sub('[0-9]+', '', tweet)\n",
    "     # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    " \n",
    "    tweets_clean = []    \n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_indonesia and # remove stopwords\n",
    "              word not in emoticons and # remove emoticons\n",
    "                word not in string.punctuation): # remove punctuation\n",
    "            #tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word) # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    " \n",
    "    return tweets_clean\n",
    "df['tweet_clean'] = df['remove_http'].apply(lambda x: clean_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[abang, nggak, kenal, bimantara, humpuss, citr...</td>\n",
       "      <td>abang nggak kenal bimantara humpuss citra lamt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>[abunawas, laen, jokowi boong, g, merugika, ra...</td>\n",
       "      <td>abunawas laen jokowi boong g merugika rakyat j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>[abunawas, pas]</td>\n",
       "      <td>abunawas pas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>[adil, pertanggungjawaban, buka]</td>\n",
       "      <td>adil pertanggungjawaban buka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>[yth, presiden, kurang, inflasi, qbat, bbm, bb...</td>\n",
       "      <td>yth presiden kurang inflasi qbat bbm bbm tdk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>[yth, presiden, mohon, maaf, sih, urgensi, ban...</td>\n",
       "      <td>yth presiden mohon maaf sih urgensi bangun ikn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>[yth, selamat, pilih, bpk, abdu, selamat, tuga...</td>\n",
       "      <td>yth selamat pilih bpk abdu selamat tugas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>[yuk, dkasih, ruang, utk, yg]</td>\n",
       "      <td>yuk dkasih ruang utk yg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>[zaman, jokowi, bikin, rame, bikin, gaduh, , ,...</td>\n",
       "      <td>zaman jokowi bikin rame bikin gaduh zaman lelu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_clean  \\\n",
       "274                                                 []   \n",
       "55   [abang, nggak, kenal, bimantara, humpuss, citr...   \n",
       "649  [abunawas, laen, jokowi boong, g, merugika, ra...   \n",
       "578                                    [abunawas, pas]   \n",
       "626                   [adil, pertanggungjawaban, buka]   \n",
       "..                                                 ...   \n",
       "727  [yth, presiden, kurang, inflasi, qbat, bbm, bb...   \n",
       "348  [yth, presiden, mohon, maaf, sih, urgensi, ban...   \n",
       "751  [yth, selamat, pilih, bpk, abdu, selamat, tuga...   \n",
       "875                      [yuk, dkasih, ruang, utk, yg]   \n",
       "850  [zaman, jokowi, bikin, rame, bikin, gaduh, , ,...   \n",
       "\n",
       "                                                 Tweet  \n",
       "274                                                     \n",
       "55   abang nggak kenal bimantara humpuss citra lamt...  \n",
       "649  abunawas laen jokowi boong g merugika rakyat j...  \n",
       "578                                       abunawas pas  \n",
       "626                       adil pertanggungjawaban buka  \n",
       "..                                                 ...  \n",
       "727  yth presiden kurang inflasi qbat bbm bbm tdk t...  \n",
       "348  yth presiden mohon maaf sih urgensi bangun ikn...  \n",
       "751           yth selamat pilih bpk abdu selamat tugas  \n",
       "875                            yuk dkasih ruang utk yg  \n",
       "850  zaman jokowi bikin rame bikin gaduh zaman lelu...  \n",
       "\n",
       "[900 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punct\n",
    "def remove_punct(text):\n",
    "    text  = \" \".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "df['Tweet'] = df['tweet_clean'].apply(lambda x: remove_punct(x))\n",
    " #=========================================================================#\n",
    "df.sort_values(\"Tweet\", inplace = True)\n",
    "df.drop(df.columns[[0,1,2,3,4]], axis = 1, inplace = True)\n",
    "df.drop_duplicates(subset =\"Tweet\", keep = 'first', inplace = True)\n",
    "df.to_csv('output.csv',encoding='utf8', index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3ed3225b5312188d346d3b7b1344bdccf6f1ab743c5303d0953b324608f438f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
